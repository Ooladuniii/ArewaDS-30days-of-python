{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISES: LEVEL 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most frequent words:\n",
      "a: 70\n",
      "li: 60\n",
      "href: 40\n",
      "class: 22\n",
      "html: 20\n",
      "gutenberg: 20\n",
      "content: 14\n",
      "div: 14\n",
      "help: 14\n",
      "meta: 13\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# URL of the text file\n",
    "url = 'http://www.gutenberg.org/files/1112/1112.txt'\n",
    "\n",
    "# Download the text from the URL\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "\n",
    "# Function to preprocess the text and find the 10 most frequent words\n",
    "def find_most_frequent_words(text, top_n=10):\n",
    "    # Remove non-alphabetic characters and convert to lowercase\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    \n",
    "    # Count the frequency of each word\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    # Get the most common words\n",
    "    most_common_words = word_counts.most_common(top_n)\n",
    "    \n",
    "    return most_common_words\n",
    "\n",
    "# Find the 10 most frequent words\n",
    "most_frequent_words = find_most_frequent_words(text)\n",
    "\n",
    "# Print the result\n",
    "print(\"Top 10 most frequent words:\")\n",
    "for word, count in most_frequent_words:\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Weight: 2.0 kg\n",
      "Max Weight: 5.0 kg\n",
      "Mean Weight: 3.2238805970149254 kg\n",
      "Median Weight: 3.0 kg\n",
      "Standard Deviation of Weight: 0.8779367862598653 kg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# API URL for cat breeds\n",
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "\n",
    "# Fetch data from the API\n",
    "response = requests.get(cats_api)\n",
    "breeds_data = response.json()\n",
    "\n",
    "# Extract weights from the data and convert to metric units\n",
    "weights = [breed['weight']['metric'] for breed in breeds_data if 'weight' in breed]\n",
    "\n",
    "# Convert weights to numeric values\n",
    "weights_numeric = [float(weight.split()[0]) for weight in weights]\n",
    "\n",
    "# Calculate statistics\n",
    "min_weight = np.min(weights_numeric)\n",
    "max_weight = np.max(weights_numeric)\n",
    "mean_weight = np.mean(weights_numeric)\n",
    "median_weight = np.median(weights_numeric)\n",
    "std_dev_weight = np.std(weights_numeric)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Min Weight: {min_weight} kg\")\n",
    "print(f\"Max Weight: {max_weight} kg\")\n",
    "print(f\"Mean Weight: {mean_weight} kg\")\n",
    "print(f\"Median Weight: {median_weight} kg\")\n",
    "print(f\"Standard Deviation of Weight: {std_dev_weight} kg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Lifespan: 10.5 years\n",
      "Max Lifespan: 19.0 years\n",
      "Mean Lifespan: 13.746268656716419 years\n",
      "Median Lifespan: 13.5 years\n",
      "Standard Deviation of Lifespan: 1.5725564658451314 years\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# API URL for cat breeds\n",
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "\n",
    "# Fetch data from the API\n",
    "response = requests.get(cats_api)\n",
    "breeds_data = response.json()\n",
    "\n",
    "# Extract lifespan data from the data\n",
    "lifespans = [breed.get('life_span') for breed in breeds_data if 'life_span' in breed]\n",
    "\n",
    "# Convert lifespans to numeric values (extracting the average if there's a range)\n",
    "lifespans_numeric = []\n",
    "for lifespan in lifespans:\n",
    "    if '-' in lifespan:\n",
    "        start, end = map(int, lifespan.split('-'))\n",
    "        lifespans_numeric.append((start + end) / 2)\n",
    "    else:\n",
    "        lifespans_numeric.append(float(lifespan))\n",
    "\n",
    "# Calculate statistics\n",
    "min_lifespan = np.min(lifespans_numeric)\n",
    "max_lifespan = np.max(lifespans_numeric)\n",
    "mean_lifespan = np.mean(lifespans_numeric)\n",
    "median_lifespan = np.median(lifespans_numeric)\n",
    "std_dev_lifespan = np.std(lifespans_numeric)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Min Lifespan: {min_lifespan} years\")\n",
    "print(f\"Max Lifespan: {max_lifespan} years\")\n",
    "print(f\"Mean Lifespan: {mean_lifespan} years\")\n",
    "print(f\"Median Lifespan: {median_lifespan} years\")\n",
    "print(f\"Standard Deviation of Lifespan: {std_dev_lifespan} years\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency Table of Country and Breed of Cats:\n",
      "Egypt: Abyssinian - 1 occurrences\n",
      "Greece: Aegean - 1 occurrences\n",
      "United States: American Bobtail - 1 occurrences\n",
      "United States: American Curl - 1 occurrences\n",
      "United States: American Shorthair - 1 occurrences\n",
      "United States: American Wirehair - 1 occurrences\n",
      "United Arab Emirates: Arabian Mau - 1 occurrences\n",
      "Australia: Australian Mist - 1 occurrences\n",
      "United States: Balinese - 1 occurrences\n",
      "United States: Bambino - 1 occurrences\n",
      "United States: Bengal - 1 occurrences\n",
      "France: Birman - 1 occurrences\n",
      "United States: Bombay - 1 occurrences\n",
      "United Kingdom: British Longhair - 1 occurrences\n",
      "United Kingdom: British Shorthair - 1 occurrences\n",
      "Burma: Burmese - 1 occurrences\n",
      "United Kingdom: Burmilla - 1 occurrences\n",
      "United States: California Spangled - 1 occurrences\n",
      "United States: Chantilly-Tiffany - 1 occurrences\n",
      "France: Chartreux - 1 occurrences\n",
      "Egypt: Chausie - 1 occurrences\n",
      "United States: Cheetoh - 1 occurrences\n",
      "United States: Colorpoint Shorthair - 1 occurrences\n",
      "United Kingdom: Cornish Rex - 1 occurrences\n",
      "Canada: Cymric - 1 occurrences\n",
      "Cyprus: Cyprus - 1 occurrences\n",
      "United Kingdom: Devon Rex - 1 occurrences\n",
      "Russia: Donskoy - 1 occurrences\n",
      "China: Dragon Li - 1 occurrences\n",
      "Egypt: Egyptian Mau - 1 occurrences\n",
      "Burma: European Burmese - 1 occurrences\n",
      "United States: Exotic Shorthair - 1 occurrences\n",
      "United Kingdom: Havana Brown - 1 occurrences\n",
      "United States: Himalayan - 1 occurrences\n",
      "Japan: Japanese Bobtail - 1 occurrences\n",
      "United States: Javanese - 1 occurrences\n",
      "Thailand: Khao Manee - 1 occurrences\n",
      "Thailand: Korat - 1 occurrences\n",
      "Russia: Kurilian - 1 occurrences\n",
      "Thailand: LaPerm - 1 occurrences\n",
      "United States: Maine Coon - 1 occurrences\n",
      "United Kingdom: Malayan - 1 occurrences\n",
      "Isle of Man: Manx - 1 occurrences\n",
      "United States: Munchkin - 1 occurrences\n",
      "United States: Nebelung - 1 occurrences\n",
      "Norway: Norwegian Forest Cat - 1 occurrences\n",
      "United States: Ocicat - 1 occurrences\n",
      "United States: Oriental - 1 occurrences\n",
      "Iran (Persia): Persian - 1 occurrences\n",
      "United States: Pixie-bob - 1 occurrences\n",
      "United States: Ragamuffin - 1 occurrences\n",
      "United States: Ragdoll - 1 occurrences\n",
      "Russia: Russian Blue - 1 occurrences\n",
      "United States: Savannah - 1 occurrences\n",
      "United Kingdom: Scottish Fold - 1 occurrences\n",
      "United States: Selkirk Rex - 1 occurrences\n",
      "Thailand: Siamese - 1 occurrences\n",
      "Russia: Siberian - 1 occurrences\n",
      "Singapore: Singapura - 1 occurrences\n",
      "United States: Snowshoe - 1 occurrences\n",
      "Somalia: Somali - 1 occurrences\n",
      "Canada: Sphynx - 1 occurrences\n",
      "Canada: Tonkinese - 1 occurrences\n",
      "United States: Toyger - 1 occurrences\n",
      "Turkey: Turkish Angora - 1 occurrences\n",
      "Turkey: Turkish Van - 1 occurrences\n",
      "United States: York Chocolate - 1 occurrences\n"
     ]
    }
   ],
   "source": [
    "# API URL for cat breeds\n",
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "\n",
    "# Fetch data from the API\n",
    "response = requests.get(cats_api)\n",
    "breeds_data = response.json()\n",
    "\n",
    "# Extract country and breed data\n",
    "country_breed_data = [(breed.get('origin', 'Unknown'), breed.get('name', 'Unknown')) for breed in breeds_data]\n",
    "\n",
    "# Create a frequency table\n",
    "frequency_table = Counter(country_breed_data)\n",
    "\n",
    "# Print the results\n",
    "print(\"Frequency Table of Country and Breed of Cats:\")\n",
    "for (country, breed), count in frequency_table.items():\n",
    "    print(f\"{country}: {breed} - {count} occurrences\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Largest Countries:\n",
      "Russian Federation: 17124442.0 sq km\n",
      "Antarctica: 14000000.0 sq km\n",
      "Canada: 9984670.0 sq km\n",
      "China: 9640011.0 sq km\n",
      "United States of America: 9629091.0 sq km\n",
      "Brazil: 8515767.0 sq km\n",
      "Australia: 7692024.0 sq km\n",
      "India: 3287590.0 sq km\n",
      "Argentina: 2780400.0 sq km\n",
      "Kazakhstan: 2724900.0 sq km\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# API URL for countries\n",
    "countries_api = 'https://restcountries.com/v2/all'\n",
    "\n",
    "# Fetch data from the API\n",
    "response = requests.get(countries_api)\n",
    "countries_data = response.json()\n",
    "\n",
    "# I. Find the 10 largest countries\n",
    "largest_countries = sorted(countries_data, key=lambda x: x.get('area', 0), reverse=True)[:10]\n",
    "\n",
    "print(\"10 Largest Countries:\")\n",
    "for country in largest_countries:\n",
    "    print(f\"{country['name']}: {country.get('area')} sq km\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 Most Spoken Languages:\n",
      "English: 91 countries\n",
      "French: 45 countries\n",
      "Arabic: 25 countries\n",
      "Spanish: 24 countries\n",
      "Portuguese: 10 countries\n",
      "Russian: 8 countries\n",
      "Dutch: 8 countries\n",
      "German: 7 countries\n",
      "Chinese: 5 countries\n",
      "Serbian: 4 countries\n"
     ]
    }
   ],
   "source": [
    "# II. Find the 10 most spoken languages\n",
    "all_languages = [language['name'] for country in countries_data for language in country.get('languages', [])]\n",
    "most_spoken_languages = dict(sorted(Counter(all_languages).items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "\n",
    "print(\"\\n10 Most Spoken Languages:\")\n",
    "for language, count in most_spoken_languages.items():\n",
    "    print(f\"{language}: {count} countries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Number of Languages: 123\n"
     ]
    }
   ],
   "source": [
    "# III. Find the total number of languages\n",
    "unique_languages = set(all_languages)\n",
    "total_languages = len(unique_languages)\n",
    "\n",
    "print(f\"\\nTotal Number of Languages: {total_languages}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch content. Status code: 404\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the UCI Machine Learning Repository\n",
    "uci_url = 'https://archive.ics.uci.edu/ml/datasets.php'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(uci_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract information, for example, titles of datasets\n",
    "    dataset_titles = [title.text.strip() for title in soup.select('.normal a b')]\n",
    "\n",
    "    # Print the titles\n",
    "    for i, title in enumerate(dataset_titles, start=1):\n",
    "        print(f\"{i}. {title}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to fetch content. Status code: {response.status_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
